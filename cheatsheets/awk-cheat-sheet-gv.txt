 AWK
 http://www.theunixschool.com/2012/09/grep-vs-awk-examples-for-pattern-search.html
 https://www.gnu.org/software/gawk/manual/html_node/String-Functions.html
 https://www.yumpu.com/en/document/view/25827537/sed-and-awk-101-hacks#
 
 Depending on the application you can call AWK once to load the file and then you can manipulate the fields within AWK.
 Typical usage advantage is when you need to read multiple patterns / values /columns / data from the same file.
 If you do that with loop & grep you most probably it will be necessary to grep many times the same file and this makes the script slow.
 Instead you can just once AWK the file and do whatever nanipulation you need inside AWK.
 For complicated data manipulation is usual to have a seperate file full with AWK code and then call AWK with -f flag (=from file) to apply the code in your file/input
 Remember the 48H log example that you need to see events logged in any minute of the 48H time frame. The use of loop and grep per minute leads to 3000 greps of the file, while you can do it with one AWK access.
 Another great advantage is that you can use as field seperator (F) anything (a char, a word, two delimiters, etc).
 Compared to cut : with cut you allowed to use only one delimiter (-d), or to define a chars range using -c (i.e -c1-10 : seperate file in character 1-10 , whatever this char is).
 echo "This is something new for us" |cut -c1-12 --> This is some # You can not combine -c with -f or with another -c, but you can print a range -c1-10, or particular chars using -c1,10,12

 echo "value1,string1;string2;string3;string4" |awk -F"[;,]" '{print $2}' -->string1
 echo "value1,string1;string2;string3;string4" |awk -F"[;,]" 'NR==1{for(i=2;i<=NF;i++)print $1","$i}'
 -->value1,string1
 -->value1,string2
 -->value1,string3
 -->value1,string4
 In case of file , separated with new lines you need to apply this a bit different version: 
 awk -F"[;,]" 'NR==1{print;next}{for(i=2;i<=NF;i++)print $1","$i}' file

 See this article for AWK reserved variables :
 http://www.thegeekstuff.com/2010/01/8-powerful-awk-built-in-variables-fs-ofs-rs-ors-nr-nf-filename-fnr/?ref=binfind.com/web

#------------#-------------##------------#-------------##------------#-------------##------------#-------------#
AWK Print lines if specific columns have same value
 awk -F ':' '$3==$4' file.txt -->  
 echo "Geo 123 bg ty 123" |awk -F" " '$2==$5' -> Geo 123 bg ty 123  # Print lines in which field 2 = field 5, otherwise returns nothing.
 echo "Geo 123 bg ty 123 Geo" |awk -F" " '$1==$6' --> Geo 123 bg ty 123 Geo # Print if field1=filed6 , meaning Geo=Geo. Works even with strings!!!

#------------#-------------##------------#-------------##------------#-------------##------------#-------------#
 Export AWK variables
 $ mkfifo fifo
 $ echo MYSCRIPT_RESULT=1 | awk '{ print > "fifo" }' &
 $ IFS== read var value < fifo
 $ eval export $var=$value

#------------#-------------##------------#-------------##------------#-------------##------------#-------------#
 Switch position of comma separated fields:
 echo "textA,textB,textC,dateD" |awk -F, '{A=$3; $3=$2; $2=A; print}' OFS=,
 textA,textC,textB,dateD
 OFS affects only the display separator. If omited space (default OFS) will be used.

 print all the lines between word1 and word2 : awk '/Tatty Error/,/suck/' a.txt

 Print up to EOF after a matched string: awk '/matched string/,0' a.txt

#------------#-------------##------------#-------------##------------#-------------##------------#-------------#
 AWK - Use multiple delimiters:
 $ awk -F"name=|ear=|xml=|/>" '{print $2} {print $4}' a.txt >b.txt
 Input: <app name="UAT/ECC/Global/MES/1206/MRP-S23"   ear="UAT/ECC/Global/MES/1206/MRP-S23.ear" xml="UAT/ECC/Glal/ME/120/MRP-  S23.xml"/>
 Output: 
 UAT/ECC/Global/MES/1206/MRP-S23   
 UAT/ECC/Glal/ME/120/MRP-  S23.xml
 Test: awk -F"name=|ear=|xml=|/>" '{print "Field1="$1} {print "Field2="$2} {print "Field3="$3} {print "Field4="$4}' a.txt
 Mind that separate {} create a newline to out file.

#------------#-------------##------------#-------------##------------#-------------##------------#-------------#
 Search for a pattern with not known occurencies:
 awk '{{for(i=1;i<=NF;i++)if($i == "name:") printf $(i+1)" "$(i+2)" "} print ""; }' yourfile
 This is usefull if we dont know how many "name:" entries exist per line
 If we know that each line has i.e 3 entries then this also works: awk -F"name:" '{print $2 $3 $4}'
 If a line has less than 3 no problem. Var $3 and/or $4 will be empty. 
 If line has more than 3 the -F solution will miss the rest entries.

 Also check this out: awk '{for(i=3;i<=NF;++i)print $i}'

#------------#-------------##------------#-------------##------------#-------------##------------#-------------#
 AWK: Produce a sed script to replace values to a file with entries from another file
 http://unix.stackexchange.com/questions/340246/how-to-replace-a-string-in-file-a-by-searching-string-map-in-file-b#340247

 Consider a user map containing multiple lines with "userid username" (seperated by space)
 Consider a text file (letter.txt) contaiining paragraphs with reference to the users as userid.
 We want to replace all userids in letter file with their realnames present in name mapping file.
 Tricky solution: Transform map file (each line) to the format 's/userid/username/g' and then call sed -f <transformed mapfile> <text file that needs replacements>
 The awk part: $ awk '{ printf("s/<@%s>/%s/g\n", $1, $2) }' user_map.txt >script.sed
 The sed part: $ sed -f script.sed letter.txt 
 
 *BASH Way: var="$(cat file.txt)";while read -r id name;do var="${var//@$id/$name}";done<mapfile.txt;echo "$var"
 
 *SED Way : while read -r id name;do sed -i "s/\@$id/$name/g" textfile.txt;done<mapfile.txt
 
 *SED Bug : File is opened and "seded" multiple times (but either the Kusulananda solution does sed multiple times, correct? - No. Does one sed with multiple replace patterns)
 On the other hand, bash way opens the file once and , makes replacements in memory ($var) and when finished just echo the $var.
 Bash solution doesnot require any external tools; it is just bash parameter expansion feature.

#------------#-------------##------------#-------------##------------#-------------##------------#-------------#
 AWK: Insert dash in string
 String: #  1  2016-05-31-1003-57S._BKSR_003_CM6
 awk '{print substr($3,0,13)"-"substr($3,14,2)}' file.txt
 Output : 2016-05-31-10-03
 alternatives:
 $ cut --output-delimiter='-' -c7-19,20-21 file.txt
 $ while IFS= read -r line;do line="${line:6:13}-${line:14:2}";echo $line;done<file.txt
 $ sed 's/..$/-\0/g' <(cut -d- -f1-4 <(cut -d" " -f5- file.txt)) #use >newfile at the end to send the results to a new file

#------------#-------------##------------#-------------##------------#-------------##------------#-------------#
 AWK Replace values upon criteria matching:
 Input:
   a b c
A 5 2 0
B 0 5 4
C 4 3 4
D 2 0 2

 Output expected (replace all fields with a value to 1)
   a b c
A 1 1 0
B 0 1 1
C 1 1 1
D 1 0 1

 AWK script : 
BEGIN { OFS = FS = "\t" }

NR != 1 {
    for (i = 2; i <= NF; ++i) {
        if ($i != "0") {
            $i = "1";
        }
    }
}

{ print }

Runit : awk -f script.awk datafile

#------------#-------------##------------#-------------##------------#-------------##------------#-------------#
AWK - Column Checker:
Input:
A B B A
A A A
B A B A
B B
A A
A B

Output : 
If all columns are the same then print just once the common characted (i.e if AAA then print A)
If columns are different then print "multi"

Code:
awk '{ for (i = 2; i <= NF; i++) { if ($i != $1) { print "multi"; next } }; print $1 }'

#------------#-------------##------------#-------------##------------#-------------##------------#-------------#
Combine multi grep pattern and cut -d' ' -f3 for multiple lines
awk '/Label 3/ { print $3 >>"F3.csv" } /Label 5/ { print $3>>"F5.csv" }'
OR
awk '/Label 3|Label 5/ { print $3 >> "F"$2".csv"}'

Consider a file with lines 
Label 3 70
Label 4 95
Label 5 100

#------------#-------------##------------#-------------##------------#-------------##------------#-------------#
AWK Print line with matched pattern (simulates grep):
awk '/word/' file.txt
GNU awk also accepts variables in the form of awk "/$variable/" file.txt
Using '!/pattern/' you invert the match (similar to grep -v)
#------------#-------------##------------#-------------##------------#-------------##------------#-------------#
AWK Use as grep with AND Operation
awk '/pattern1/&&/pattern2/'
#------------#-------------##------------#-------------##------------#-------------##------------#-------------#
AWK Print a line if columns are equal to 5 (ps: columns separated by "|")
awk -F \| 'NF==5' data3

#------------#-------------##------------#-------------##------------#-------------##------------#-------------#
AWK Count lines
awk '{ $0 = NR "\t" $0 } 1' file.txt | tail

Counting Alternatives:
grep -n ^ file.txt | sed 's/:/\t/' | tail
sed = file.txt | sed 'N;s/\n/\t/' | tail
pr -n -t -l 1 file.txt | tail
nl /boot/config-4.9.0-1-amd64 |tail

#------------#-------------##------------#-------------##------------#-------------##------------#-------------#
AWK : Simulate agrep (grep with AND) for patterns read from a file:
http://unix.stackexchange.com/questions/341076/how-to-find-all-files-containing-various-strings-from-a-long-list-of-string-comb
Basic: awk '/pattern1/ && /pattern2/'
while IFS= read -r line;do awk "$line" *.txt;done<./tmp/d1.txt

Above will print in screen the matched lines of all txt files.
If we need to print only the filename and not the matched contents then awk must be used like this:
awk "$line""{print FILENAME}" *.txt

In order this to work , search terms in file should be in format /term1/ && /term2/ && /term3/ etc.
I the example given in link , pattern file contains lines like this:
"surveillance data" "surveillance technology" "cctv camera"

Which are converted to awk format like this:
$ sed 's/" "/\/ \&\& \//g; s/^"\|"$/\//g' ./tmp/d1.txt
> /surveillance data/ && /surveillance technology/ && /cctv camera/

Alternativelly we could use :

(a) agrep by formatting the data in the form of 
pattern1;pattern2;pattern3 
and then using: while IFS= read -r line;do agrep "$line" *.txt;done<./tmp/d1.txt

(b) classic grep with xargs -r : grep -l pattern1 * |xargs -r grep -l pattern2 |xargs -r grep -l pattern3
The -l instructs grep to print filename . Usefull info for the next grep.
If we just want to multi grep with and on the data then even this should work:
grep pattern1 file |grep pattern2 |grep pattern3
The final output would include all three patterns. 

#------------#-------------##------------#-------------##------------#-------------##------------#-------------#
AWK print a line before the pattern match and also the line containing the pattern 'Solaris': 
$ awk '/Solaris/{print x;print;next}{x=$0;}' file

Every line read is stored in the variable x. Hence, when the pattern matches, x contains the previous line. 
And hence, by printing the $0 and x, the current line $0 and the previous line x is printed. 

#------------#-------------##------------#-------------##------------#-------------##------------#-------------#
AWK print the previous, the pattern matching line and next line
$ awk '/Solaris/{print x;print;getline;print;next}{x=$0;}' file
x: gets the previous line
print: just prints the current line (stored at $0)
getline : stores next line to $0.
The last print prints again $0 which now is the next line due to previous getline  

#------------#-------------##------------#-------------##------------#-------------##------------#-------------#
AWK Replace /Delete String
awk '{ gsub(",","",$3); print $3 }' /tmp/data.txt
Replaces , with null in field $3 and then prints $3
If $3 is not provided , then gsub operation is performed in $0=Whole Record = Whole line

#------------#-------------##------------#-------------##------------#-------------##------------#-------------#
AWK If then 
https://www.yumpu.com/en/document/view/25827537/sed-and-awk-101-hacks#
awk -F'"' '{if ($0!="") print $1"\""$2" || "$2"\""$3;}' e.txt
awk '{if ($3 =="" || $4 == "" || $5 == "")print "Some score for the student",$1,"is missing";'}' student-marks
awk '$4<900 || $5<=5' file.txt #Prints the records in which $4 is less than 900 and $5 is -le 5
#Can combined with {print $2} to print a particular field instead of the whole line.
awk '$3==$4' file #prints records/lines only if $3 field = $5 field
awk '$2=="Tennis" #prints lines where #2 is tennis
awk '$2 ~ "Tennis" #prints lines where #2 contains tennis
#------------#-------------##------------#-------------##------------#-------------##------------#-------------#
AWK If then else
http://www.thegeekstuff.com/2010/02/awk-conditional-statements
1. awk '{if ($3 >=35 && $4 >= 35 && $5 >= 35) print $0,"=>","Pass";else print $0,"=>","Fail";}'

#------------#-------------##------------#-------------##------------#-------------##------------#-------------#
AWK If then else and Replace

awk -F'"' '{if ($0=="") print $0;else {a=$2;gsub("lbk_addcolumn","ColumnAdd",$2);gsub("lbk_dropcolumn","ColumnDrop",$2);print $1"\""$2" || "a"\""$3;}}' e.txt

# Alternative - more easy to read:
# $ a=$(awk -F'"' '{if (($0=="")) print $0;else print $1"\""$2" || "$2"\""$3}' file.txt)
# $ sed 's/lbk_addcolumn/ColumnAdd/;s/lbk_dropcolumn/ColumnDrop/' <<<"$a
# Or Even with process substitution: 
# $sed 's/lbk_addcolumn/ColumnAdd/;s/lbk_dropcolumn/ColumnDrop/' <(awk -F'"' '{if (($0=="")) print $0;else print $1"\""$2" || "$2"\""$3}' file.txt)

This prints blank lines straight away (unprocessed) and performs all operation if lines are not blank.
You need to apply {} in if-then-else if you need more than one commands to be executed as a group. 
If you dont enclose commands in{} only the first command (up to first ;) is executed and then if condition check stops. 
Rest commands will be executed as a continuation of the code after if-then-else

For Input like this : 	
x;x;x;x;x;x;cmd="lbk_addcolumn TABLE_NAME_1 COLUMN_X";x;x;x;x

x;x;x;x;x;x;cmd="lbk_dropcolumn TABLE_NAME_2 COLUMN_Y";x;x;x;x

Gives Output like this:	
x;x;x;x;x;x;cmd="ColumnAdd TABLE_NAME_1 COLUMN_X || lbk_addcolumn TABLE_NAME_1 COLUMN_X";x;x;x;x

x;x;x;x;x;x;cmd="ColumnDrop TABLE_NAME_2 COLUMN_Y || lbk_dropcolumn TABLE_NAME_2 COLUMN_Y";x;x;x;x
(Ps: mind that blanc line is preserved - not processed. )


